%!TEX root=../main.tex
% Chapter Template

\chapter{Conclusion} % Main chapter title

\label{Chapter8} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Problem definition and research questions}

The original problem definition was supplied by Struct A/S and involves them using their logged user activity data to create a personalized experience for the users. The answer to this is an API giving tailored product recommendations to the end user based on his/her behavior on the website. The API also allows for an easy way to add and maintain data about each visitor to keep recommendations up to date and relevant. \\
The problem definition derived the following three research questions "How can you optimally store and access data in a scalable way?",  "How can this data be maintained and updated easily after deployment?" and "How can you utilize the organized data to generate tailored product recommendations for the end user?". These questions are answered below.

\subsection{How can you optimally store and access data in a scalable way?}
MongoDB, a No-SQL database, was chosen in order to accomplish scalable accessing and storing of the data provided by Struct A/S. MongoDB provides scaling functionalities due to its denormalized data which can more easily be spread across multiple servers \ref{SQLvsNOSQL}. No-SQL service platforms such as Azure or Amazon WebServices has built in scaling functions \cite{azureNoSQL} which gives the distinct advantage that even if the data grows exponentially the hardware can keep up. Accessing all information about a certain user or product is also fast due to the denormalized structure without performing multiple joins or complex quires as would be the case with standard SQL databases. Overall MongoDB is a good fit for this type of project with growing data needs.

\subsection{How can this data be maintained and updated easily after deployment?}
Maintaining and updating the data is as simple as calling the correct API functions as new data is produced. When a new visitor visits the site one API function will store the visitor in the database, similarly new behavior data is stored by calling another API function. These API functions can be called asynchronously meaning no extra load times for the end user, which is important in the online world. \\
Using Docker allows for easy updates and maintenance of the API as pushing and pulling new docker images from the Docker Hub is simple.

\subsection{How can you utilize the organized data to generate tailored product recommendations for the end user?}
The data can be utilized through datamining. The datamining technique used to generate product recommendations in the project is Item-to-Item collaborative filtering. This process creates links between products based on their similarity and end users can thereby receive product recommendations based on the products they have already looked at. The recommendations are based on the entire user base and assumes users have similar tastes and purchasing patterns.

\section{Requirements fulfillment}
The requirements engineering process created \textbf{15} functional and 4 non-functional requirements. Of these requirements the most important one is F01 which is successfully met. functional requirements F02, F03, F05 and F06 have also been met. The remaining functional requirements are not met but are not imperative for generating product recommendations. The API is developed in ASP.NET core, the data is stored in a No-SQL database, the API is accessible through Amazon WebServices and product recommendations are generated in less than 40ms which means all non-functional requirements have been met.
